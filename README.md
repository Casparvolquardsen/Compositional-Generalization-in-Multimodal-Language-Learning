# Compositional Generalization in Multimodal Language Learning

This repository shares the most important sources used for the reasearch paper "More Diverse Training, Better Compositionality! Evidence from Multimodal Language Learning" by Caspar Volquardsen, Jae Hee Lee, Cornelius Weber, and Stefan Wermter. This paper was accepted to the International Conference on Artificial Neural Networks 2022 (ICANN 2022) in Bristol for an oral presentation and published in the [proceedings](https://doi.org/10.1007/978-3-031-15934-3_35).

This repository also includes the sources used to generate the Multimodal-Robot-Simulation dataset. This is implemented for [CoppeliaSim](https://www.coppeliarobotics.com "CoppeliaSim") educational version using [PyRep](https://github.com/stepjam/PyRep "PyRep GitHub"). The sources were originally provided by Aaron Eisermann and adapted by Caspar Volquardsen.

Referenced paper:
Volquardsen, C., Lee, J.H., Weber, C., Wermter, S. (2022). More Diverse Training, Better Compositionality! Evidence from Multimodal Language Learning. In: Pimenidis, E., Angelov, P., Jayne, C., Papaleonidas, A., Aydin, M. (eds) Artificial Neural Networks and Machine Learning â€“ ICANN 2022. ICANN 2022. Lecture Notes in Computer Science, vol 13531. Springer, Cham. https://doi.org/10.1007/978-3-031-15934-3_35
